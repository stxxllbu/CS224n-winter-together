{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f82b0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shaozhetao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import batch_iter\n",
    "from vocab import Vocab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unsqueeze dec_hidden from dec_hidden=(b, h) to dec_hidden=(b, h, 1）\n",
    "# unsqueeze means add a new dim of 1 to the index\n",
    "unsqueeze_dec_hidden = dec_hidden.unsqueeze(2)\n",
    "\n",
    "e_t = torch.bmm(enc_hiddens_proj, unsqueeze_dec_hidden).squeeze(2)  # enc_hiddens_proj=(b, src_len, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ba0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, h = 4, 9\n",
    "dec_hidden = torch.randn(b, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9804b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueeze_dec_hidden = dec_hidden.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43697503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueeze_dec_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914ac7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens_proj=torch.randn(b, 3, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36e63f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a450d790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(enc_hiddens_proj, unsqueeze_dec_hidden).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c8b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path, source):\n",
    "    # Understood\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    @param source (str): \"tgt\" or \"src\" indicating whether text\n",
    "        is of the source language or target language\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = nltk.word_tokenize(line)\n",
    "        # only append <s> and </s> to the target sentence\n",
    "        if source == 'tgt':\n",
    "            sent = ['<s>'] + sent + ['</s>']\n",
    "        data.append(sent)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d5e7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 5\n",
    "# EMBED_SIZE = 4\n",
    "# HIDDEN_SIZE = 3\n",
    "# DROPOUT_RATE = 0.0\n",
    "# seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae79a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data & vocabulary\n",
    "train_data_src = read_corpus('./sanity_check_en_es_data/train_sanity_check.es', 'src')\n",
    "train_data_tgt = read_corpus('./sanity_check_en_es_data/train_sanity_check.en', 'tgt')\n",
    "train_data = list(zip(train_data_src, train_data_tgt))\n",
    "\n",
    "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    src_sents = src_sents\n",
    "    tgt_sents = tgt_sents\n",
    "    break\n",
    "vocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5268c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = json.load(open('./sanity_check_en_es_data/char_vocab_sanity_check.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e63245a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "513fc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '{': 1,\n",
       " '}': 2,\n",
       " '<unk>': 3,\n",
       " 'a': 4,\n",
       " 'b': 5,\n",
       " 'c': 6,\n",
       " 'd': 7,\n",
       " 'e': 8,\n",
       " 'f': 9,\n",
       " 'g': 10,\n",
       " 'h': 11,\n",
       " 'i': 12,\n",
       " 'j': 13,\n",
       " 'k': 14,\n",
       " 'l': 15,\n",
       " 'm': 16,\n",
       " 'n': 17,\n",
       " 'o': 18,\n",
       " 'p': 19,\n",
       " 'q': 20,\n",
       " 'r': 21,\n",
       " 's': 22,\n",
       " 't': 23,\n",
       " 'u': 24,\n",
       " 'v': 25,\n",
       " 'w': 26,\n",
       " 'x': 27,\n",
       " 'y': 28,\n",
       " 'z': 29}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5b6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee0ce20",
   "metadata": {},
   "source": [
    "### Let's do a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "90e4cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_char = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a62bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pad_token_idx = char2id['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0fb96b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "charEmbedding = nn.Embedding(95, e_char, char_pad_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "07b317db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 12])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape#.torch.Size([8, 4, 12]) sen_len, batch, m_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75583e1c",
   "metadata": {},
   "source": [
    "###  Getting output, now CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f488f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = charEmbedding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3aee04d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2049, -1.4665,  2.5728,  ...,  0.1126, -0.9009,  0.5060],\n",
       "         [ 0.6264, -0.1826,  0.1747,  ..., -1.1034, -1.0896,  1.3063],\n",
       "         [-0.4064,  0.8771,  0.7678,  ..., -0.0860,  2.1354, -1.2489],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2049, -1.4665,  2.5728,  ...,  0.1126, -0.9009,  0.5060],\n",
       "         [ 0.0515,  0.9324, -0.6278,  ...,  0.9818,  0.4140,  0.7677],\n",
       "         [-1.3281, -0.4089,  0.5356,  ..., -1.4368,  0.9211, -0.8499],\n",
       "         ...,\n",
       "         [ 1.4147,  0.9576, -0.2676,  ...,  0.6742,  0.4508, -0.5939],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2049, -1.4665,  2.5728,  ...,  0.1126, -0.9009,  0.5060],\n",
       "         [ 0.6264, -0.1826,  0.1747,  ..., -1.1034, -1.0896,  1.3063],\n",
       "         [-0.4064,  0.8771,  0.7678,  ..., -0.0860,  2.1354, -1.2489],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2049, -1.4665,  2.5728,  ...,  0.1126, -0.9009,  0.5060],\n",
       "         [ 0.0515,  0.9324, -0.6278,  ...,  0.9818,  0.4140,  0.7677],\n",
       "         [-1.3281, -0.4089,  0.5356,  ..., -1.4368,  0.9211, -0.8499],\n",
       "         ...,\n",
       "         [ 1.4147,  0.9576, -0.2676,  ...,  0.6742,  0.4508, -0.5939],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "202e6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "CS224N 2019-20: Homework 5\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    # Remember to delete the above 'pass' after your implementation\n",
    "    ### YOUR CODE HERE for part 1g\n",
    "    def __init__(self, e_char, filters, padding=1, kernel_size=5):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.e_char = e_char\n",
    "        self.m_word = m_word\n",
    "        self.filters = filters\n",
    "        self.padding = padding\n",
    "        self.k = kernel_size\n",
    "\n",
    "        self.conv1d = None\n",
    "        self.maxpool = None\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=self.e_char,\n",
    "            out_channels=self.filters,\n",
    "            kernel_size=self.k,\n",
    "            stride=1,\n",
    "            padding=self.padding,\n",
    "            padding_mode='zeros',\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, xemb: torch.Tensor):\n",
    "        # xemb #shape (batch, m_word, e_char)\n",
    "        # xreshape #shape (batch, e_char, m_word)\n",
    "        # W #shape (filter, e_char, k)\n",
    "\n",
    "        m_word = xemb.shape[-2]\n",
    "        x_reshaped = xemb.permute(0, 1, 3, 2)\n",
    "        x_conv = self.conv1d(x_reshaped)\n",
    "        x_conv = F.relu(x_conv)\n",
    "\n",
    "        maxpool = nn.MaxPool1d(kernel_size=m_word + 2 * self.padding - self.k + 1)\n",
    "        x_conv_out = maxpool(x_conv)\n",
    "\n",
    "        return x_conv_out\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9da77538",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(e_char, filters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4e243d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2e507238",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.permute(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "413ab0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 50, 12])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "29494180",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.randn(2,4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "05f0e7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0462793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.randn(50, 30, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d99a4805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 30, 21])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5bdddabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = nn.Conv1d(\n",
    "    in_channels=30,\n",
    "    out_channels=3,\n",
    "    kernel_size=5,\n",
    "    stride=1,\n",
    "    padding=1,\n",
    "    padding_mode='zeros',\n",
    "    bias=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "41216608",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.randn(50,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c53d714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_proj = nn.Linear(3, 3, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b4689789",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (150x1 and 3x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k5/fdqlr97d7wx91475l7b4ys640000gn/T/ipykernel_21372/2248721026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mlds/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlds/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlds/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (150x1 and 3x3)"
     ]
    }
   ],
   "source": [
    "w_proj(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40bce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143abec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1a42c231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5eb0988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9172],\n",
       "         [-0.0972],\n",
       "         [ 1.2620],\n",
       "         [ 1.0838]],\n",
       "\n",
       "        [[ 1.2783],\n",
       "         [ 1.4607],\n",
       "         [ 1.5482],\n",
       "         [ 0.6417]]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dede6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents_char(sents, char_pad_token):\n",
    "    \"\"\" Pad list of sentences according to the longest sentence in the batch and longest words in all sentences.\n",
    "    @param sents (list[list[list[int]]]): list of sentences, result of `words2charindices()`\n",
    "        from `vocab.py`\n",
    "    @param char_pad_token (int): index of the character-padding token\n",
    "    @returns sents_padded (list[list[list[int]]]): list of sentences where sentences/words shorter\n",
    "        than the max length sentence/word are padded out with the appropriate pad token, such that\n",
    "        each sentence in the batch now has same number of words and each word has an equal\n",
    "        number of characters\n",
    "        Output shape: (batch_size, max_sentence_length, max_word_length)\n",
    "    \"\"\"\n",
    "\n",
    "    sents_padded = []\n",
    "    max_word_length = max(len(w) for s in sents for w in s )\n",
    "    max_sent_len = max(len(s) for s in sents)\n",
    "    batch_size = len(sents)\n",
    "\n",
    "    for k in range(batch_size):\n",
    "        sentence = sents[k]\n",
    "        sent_padded = []\n",
    "\n",
    "        for w in sentence:\n",
    "            data = [c for c in w] + [char_pad_token for _ in range(max_word_length-len(w))]\n",
    "            if len(data) > max_word_length:\n",
    "                data = data[:max_word_length]\n",
    "            sent_padded.append(data)\n",
    "\n",
    "        sent_padded = sent_padded[:max_sent_len] + [[char_pad_token]*max_word_length] * max(0, max_sent_len - len(sent_padded))\n",
    "        sents_padded.append(sent_padded)\n",
    "\n",
    "    return sents_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c1e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = pad_sents_char(src_sents, '<char>')\n",
    "# xx\n",
    "char_list = list(\n",
    "            \"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]\"\"\")\n",
    "char2id = dict()  # Converts characters to integers\n",
    "char2id['∏'] = 0  # <pad> token\n",
    "char2id['{'] = 1  # start of word token\n",
    "char2id['}'] = 2  # end of word token\n",
    "char2id['Û'] = 3  # <unk> token\n",
    "for i, c in enumerate(char_list):\n",
    "    char2id[c] = len(char2id)\n",
    "char_pad = char2id['∏']\n",
    "char_unk = char2id['Û']\n",
    "start_of_word = char2id[\"{\"]\n",
    "end_of_word = char2id[\"}\"]\n",
    "assert start_of_word + 1 == end_of_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f239da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['Human', ':', 'What', 'do', 'we', 'want', '?'], ['Computer', ':', 'Natural', 'language', 'processing', '!'], ['Human', ':', 'When', 'do', 'we', 'want', 'it', '?'], ['Computer', ':', 'When', 'do', 'we', 'want', 'what', '?']]\n",
    "sentence_length = 8\n",
    "BATCH_SIZE = 4\n",
    "word_length = 12\n",
    "vocabEntry = VocabEntry()\n",
    "output = vocabEntry.to_input_tensor_char(sentences, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269c3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef7af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b01b175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from docopt import docopt\n",
    "from itertools import chain\n",
    "import json\n",
    "import torch\n",
    "from typing import List\n",
    "from utils import read_corpus, pad_sents, pad_sents_char\n",
    "\n",
    "\n",
    "class VocabEntry(object):\n",
    "    \"\"\" Vocabulary Entry, i.e. structure containing either\n",
    "    src or tgt language terms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, word2id=None):\n",
    "        \"\"\" Init VocabEntry Instance.\n",
    "        @param word2id (dict): dictionary mapping words 2 indices\n",
    "        \"\"\"\n",
    "        if word2id:\n",
    "            self.word2id = word2id\n",
    "        else:\n",
    "            self.word2id = dict()\n",
    "            self.word2id['<pad>'] = 0  # Pad Token\n",
    "            self.word2id['<s>'] = 1  # Start Token\n",
    "            self.word2id['</s>'] = 2  # End Token\n",
    "            self.word2id['<unk>'] = 3  # Unknown Token\n",
    "        self.unk_id = self.word2id['<unk>']\n",
    "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
    "\n",
    "        ## Additions to the A4 code:\n",
    "        self.char_list = list(\n",
    "            \"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]\"\"\")\n",
    "\n",
    "        self.char2id = dict()  # Converts characters to integers\n",
    "        self.char2id['∏'] = 0  # <pad> token\n",
    "        self.char2id['{'] = 1  # start of word token\n",
    "        self.char2id['}'] = 2  # end of word token\n",
    "        self.char2id['Û'] = 3  # <unk> token\n",
    "        for i, c in enumerate(self.char_list):\n",
    "            self.char2id[c] = len(self.char2id)\n",
    "        self.char_pad = self.char2id['∏']\n",
    "        self.char_unk = self.char2id['Û']\n",
    "        self.start_of_word = self.char2id[\"{\"]\n",
    "        self.end_of_word = self.char2id[\"}\"]\n",
    "        assert self.start_of_word + 1 == self.end_of_word\n",
    "\n",
    "        self.id2char = {v: k for k, v in self.char2id.items()}  # Converts integers to characters\n",
    "        ## End additions to the A4 code\n",
    "\n",
    "    def __getitem__(self, word):\n",
    "        \"\"\" Retrieve word's index. Return the index for the unk\n",
    "        token if the word is out of vocabulary.\n",
    "        @param word (str): word to look up.\n",
    "        @returns index (int): index of word\n",
    "        \"\"\"\n",
    "        return self.word2id.get(word, self.unk_id)\n",
    "\n",
    "    def __contains__(self, word):\n",
    "        \"\"\" Check if word is captured by VocabEntry.\n",
    "        @param word (str): word to look up\n",
    "        @returns contains (bool): whether word is contained\n",
    "        \"\"\"\n",
    "        return word in self.word2id\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        \"\"\" Raise error, if one tries to edit the VocabEntry.\n",
    "        \"\"\"\n",
    "        raise ValueError('vocabulary is readonly')\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Compute number of words in VocabEntry.\n",
    "        @returns len (int): number of words in VocabEntry\n",
    "        \"\"\"\n",
    "        return len(self.word2id)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\" Representation of VocabEntry to be used\n",
    "        when printing the object.\n",
    "        \"\"\"\n",
    "        return 'Vocabulary[size=%d]' % len(self)\n",
    "\n",
    "    def id2word(self, wid):\n",
    "        \"\"\" Return mapping of index to word.\n",
    "        @param wid (int): word index\n",
    "        @returns word (str): word corresponding to index\n",
    "        \"\"\"\n",
    "        return self.id2word[wid]\n",
    "\n",
    "    def add(self, word):\n",
    "        \"\"\" Add word to VocabEntry, if it is previously unseen.\n",
    "        @param word (str): word to add to VocabEntry\n",
    "        @return index (int): index that the word has been assigned\n",
    "        \"\"\"\n",
    "        if word not in self:\n",
    "            wid = self.word2id[word] = len(self)\n",
    "            self.id2word[wid] = word\n",
    "            return wid\n",
    "        else:\n",
    "            return self[word]\n",
    "\n",
    "    def words2charindices(self, sents):\n",
    "        \"\"\" Convert list of sentences of words into list of list of list of character indices.\n",
    "        @param sents (list[list[str]]): sentence(s) in words\n",
    "        @return word_ids (list[list[list[int]]]): sentence(s) in indices\n",
    "        \"\"\"\n",
    "        return [[[self.char2id.get(c, self.char_unk) for c in (\"{\" + w + \"}\")] for w in s] for s in sents]\n",
    "\n",
    "    def words2indices(self, sents):\n",
    "        \"\"\" Convert list of sentences of words into list of list of indices.\n",
    "        @param sents (list[list[str]]): sentence(s) in words\n",
    "        @return word_ids (list[list[int]]): sentence(s) in indices\n",
    "        \"\"\"\n",
    "        return [[self[w] for w in s] for s in sents]\n",
    "\n",
    "    def indices2words(self, word_ids):\n",
    "        \"\"\" Convert list of indices into words.\n",
    "        @param word_ids (list[int]): list of word ids\n",
    "        @return sents (list[str]): list of words\n",
    "        \"\"\"\n",
    "        return [self.id2word[w_id] for w_id in word_ids]\n",
    "\n",
    "    def to_input_tensor_char(self, sents: List[List[str]], device: torch.device) -> torch.Tensor:\n",
    "        \"\"\" Convert list of sentences (words) into tensor with necessary padding for\n",
    "        shorter sentences.\n",
    "\n",
    "        @param sents (List[List[str]]): list of sentences (words)\n",
    "        @param device: device on which to load the tensor, i.e. CPU or GPU\n",
    "\n",
    "        @returns sents_var: tensor of (max_sentence_length, batch_size, max_word_length)\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE for part 1e\n",
    "        ### TODO:\n",
    "        ###     - Use `words2charindices()` from this file, which converts each character to its corresponding index in the\n",
    "        ###       character-vocabulary.\n",
    "        ###     - Use `pad_sents_char()` from utils.py, which pads all words to max_word_length of all words in the batch,\n",
    "        ###       and pads all sentences to max length of all sentences in the batch. Read __init__ to see how to get\n",
    "        ###       index of character-padding token\n",
    "        ###     - Connect these two parts to convert the resulting padded sentences to a torch tensor.\n",
    "        ### HINT:\n",
    "        ###     - You may find .contiguous() useful after reshaping. Check the following links for more details:\n",
    "        ###         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.contiguous\n",
    "        ###         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
    "\n",
    "        char_sents = self.words2charindices(sents)\n",
    "        res = torch.tensor(pad_sents_char(char_sents, char_pad_token=self.char_pad)) #b, max_sent_len, max_word\n",
    "        res = res.permute(1, 0, 2).contiguous() # max_sent_len, b, max_word\n",
    "\n",
    "        return res\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def to_input_tensor(self, sents: List[List[str]], device: torch.device) -> torch.Tensor:\n",
    "        \"\"\" Convert list of sentences (words) into tensor with necessary padding for \n",
    "        shorter sentences.\n",
    "\n",
    "        @param sents (List[List[str]]): list of sentences (words)\n",
    "        @param device: device on which to load the tesnor, i.e. CPU or GPU\n",
    "\n",
    "        @returns sents_var: tensor of (max_sentence_length, batch_size)\n",
    "        \"\"\"\n",
    "        word_ids = self.words2indices(sents)\n",
    "        sents_t = pad_sents(word_ids, self['<pad>'])\n",
    "        sents_var = torch.tensor(sents_t, dtype=torch.long, device=device)\n",
    "        return torch.t(sents_var)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_corpus(corpus, size, freq_cutoff=2):\n",
    "        \"\"\" Given a corpus construct a Vocab Entry.\n",
    "        @param corpus (list[str]): corpus of text produced by read_corpus function\n",
    "        @param size (int): # of words in vocabulary\n",
    "        @param freq_cutoff (int): if word occurs n < freq_cutoff times, drop the word\n",
    "        @returns vocab_entry (VocabEntry): VocabEntry instance produced from provided corpus\n",
    "        \"\"\"\n",
    "        vocab_entry = VocabEntry()\n",
    "        word_freq = Counter(chain(*corpus))\n",
    "        valid_words = [w for w, v in word_freq.items() if v >= freq_cutoff]\n",
    "        print('number of word types: {}, number of word types w/ frequency >= {}: {}'\n",
    "              .format(len(word_freq), freq_cutoff, len(valid_words)))\n",
    "        top_k_words = sorted(valid_words, key=lambda w: word_freq[w], reverse=True)[:size]\n",
    "        for word in top_k_words:\n",
    "            vocab_entry.add(word)\n",
    "        return vocab_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8169d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82457b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d0fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c43103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2charindices(sents):\n",
    "    \"\"\" Convert list of sentences of words into list of list of list of character indices.\n",
    "    @param sents (list[list[str]]): sentence(s) in words\n",
    "    @return word_ids (list[list[list[int]]]): sentence(s) in indices\n",
    "    \"\"\"\n",
    "    return [[[char2id.get(c, char_unk) for c in (\"{\" + w + \"}\")] for w in s] for s in sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d459c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "char2id =json.load(open('./sanity_check_en_es_data/char_vocab_sanity_check.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "524851bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2char = {v: k for k, v in char2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8151e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(2).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f073e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39541749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7a299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1320e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429306b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f07e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c20fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c64684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0996fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[[1., 1., 1., 1.],\n",
    "              [-2, -2, -2., -2.]],\n",
    "             [[2, 2, 1, 1],\n",
    "              [0.5, 0.5, 0, 0]]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d52e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape:   torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"input tensor shape:  \", x.size())\n",
    "x = x.permute(0, 2, 1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d7e18cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape:   torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"input tensor shape:  \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398de7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80a89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f53d829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50, 6])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 6, 50)\n",
    "xreshaped = x.permute(0, 2, 1)\n",
    "xreshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55184692",
   "metadata": {},
   "outputs": [],
   "source": [
    "xreshaped #(e_char=4, m_word=6)\n",
    "b, e_char, m_word = xreshaped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d94cf816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "35461932",
   "metadata": {},
   "outputs": [],
   "source": [
    "xconv = conv1d(xreshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd7bcfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 4])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xconv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fbaf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_word #6\n",
    "# k # 5\n",
    "# padding # 1\n",
    "# 6-5+2+1 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10ab520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool1d(kernel_size=m_word+2*1-5+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3564b11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaozhetao/miniconda3/envs/mlds/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "xout = maxpool(xconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f804fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c6551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45229985",
   "metadata": {},
   "outputs": [],
   "source": [
    "xccc = F.relu(xconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f75842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xccc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9096a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e2e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53ac9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "CS224N 2019-20: Homework 5\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    # Remember to delete the above 'pass' after your implementation\n",
    "    ### YOUR CODE HERE for part 1g\n",
    "    def __init__(self, e_char, filters, padding=1, kernel_size=5):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.e_char = e_char\n",
    "        self.m_word = m_word\n",
    "        self.filters = filters\n",
    "        self.padding = padding\n",
    "        self.k = kernel_size\n",
    "\n",
    "        self.conv1d = None\n",
    "        self.maxpool = None\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=self.e_char,\n",
    "            out_channels=self.filters,\n",
    "            kernel_size=self.k,\n",
    "            stride=1,\n",
    "            padding=self.padding,\n",
    "            padding_mode='zeros',\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, xemb: torch.Tensor):\n",
    "        # xemb #shape (batch, m_word, e_char)\n",
    "        # xreshape #shape (batch, e_char, m_word)\n",
    "        # W #shape (filter, e_char, k)\n",
    "\n",
    "        m_word = xemb.shape[1]\n",
    "        x_reshaped = xemb.permute(0, 2, 1)\n",
    "        x_conv = self.conv1d(x_reshaped)\n",
    "        x_conv = F.relu(x_conv)\n",
    "\n",
    "        maxpool = nn.MaxPool1d(kernel_size=m_word + 2 * self.padding - self.k + 1)\n",
    "        x_conv_out = maxpool(x_conv)\n",
    "\n",
    "        return x_conv_out\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce12c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af814f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7c66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8b8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c7864d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Highway(nn.Module):\n",
    "    # Remember to delete the above 'pass' after your implementation\n",
    "    ### YOUR CODE HERE for part 1f\n",
    "    def __init__(self, eword_size):\n",
    "        super(Highway, self).__init__()\n",
    "        self.eword_size = eword_size\n",
    "\n",
    "        self.w_proj = nn.Linear(self.eword_size, self.eword_size, bias=True)\n",
    "        # self.b_proj = None\n",
    "        self.w_gate = nn.Linear(self.eword_size, self.eword_size, bias=True)\n",
    "        # self.b_gate = None\n",
    "        self.highway_ReLU = nn.ReLU()\n",
    "\n",
    "    def forward(self, x_conv: torch.Tensor):\n",
    "        x_proj_pre = self.w_proj(x_conv)\n",
    "        x_proj = self.highway_ReLU(x_proj_pre)\n",
    "        x_gate_pre = self.w_gate(x_proj)\n",
    "        x_gate = F.sigmoid(x_gate_pre)\n",
    "\n",
    "        x_highway = x_gate*x_proj + (1-x_gate)*x_conv\n",
    "\n",
    "        return x_highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "01ecddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(6, 4)#.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a19521b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aefaba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eword_size = 4\n",
    "# w_proj = nn.Linear(eword_size, eword_size, bias=True)\n",
    "# w_gate = nn.Linear(eword_size, eword_size, bias=True)\n",
    "# highway_ReLU = nn.ReLU()\n",
    "\n",
    "# x_conv = x\n",
    "# x_proj_pre = w_proj(x_conv)\n",
    "# x_proj = highway_ReLU(x_proj_pre)\n",
    "# x_gate_pre = w_gate(x_proj)\n",
    "# x_gate = F.sigmoid(x_gate_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d3367583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5411, 0.0000, 0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_proj*x_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0b20594d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'batch1' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k5/fdqlr97d7wx91475l7b4ys640000gn/T/ipykernel_78971/766914715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'batch1' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "torch.bmm(x_gate, x_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "827c52c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5705, 0.5203, 0.5695, 0.5528]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3923e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = Highway(eword_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "10ea9704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3054, -0.0800, -0.6386, -0.5675],\n",
       "        [ 0.4913,  0.9047,  0.5233,  0.1609],\n",
       "        [ 0.4192,  0.2976, -0.3603, -0.1999],\n",
       "        [-0.0752,  0.5150,  1.0933,  0.3429],\n",
       "        [ 0.6722,  0.1355, -0.4967,  0.1334],\n",
       "        [-0.2583, -0.0197,  0.5127,  0.1623]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb7fe3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# yy = torch.t(yy)#.shape # [b, max_sent_len, max_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b2097a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 40, 16])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adaa507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1, 15, 30,  ...,  0,  0,  0],\n",
       "         [ 1, 41, 41,  ...,  0,  0,  0],\n",
       "         [ 1, 33, 34,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 1, 58, 56,  ...,  0,  0,  0],\n",
       "         [ 1, 30, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 68,  2,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 15, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 38,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 44,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 15, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 31, 34,  ...,  0,  0,  0],\n",
       "         [ 1, 33, 34,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 19, 34,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 34, 48,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1,  6, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 42, 50,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 42,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc66f7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1, 15, 30,  ...,  0,  0,  0],\n",
       "         [ 1, 15, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 15, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 19, 34,  ...,  0,  0,  0],\n",
       "         [ 1,  6, 44,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 41, 41,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 38,  ...,  0,  0,  0],\n",
       "         [ 1, 31, 34,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 42, 50,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 33, 34,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 44,  ...,  0,  0,  0],\n",
       "         [ 1, 33, 34,  ...,  0,  0,  0],\n",
       "         [ 1, 34, 48,  ...,  0,  0,  0],\n",
       "         [ 1, 43, 42,  ...,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1, 58, 56,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 30, 44,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 68,  2,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.permute((1,0,2)).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d25e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = src_sents\n",
    "max_word_length = max(len(w) for s in ss for w in s )\n",
    "\n",
    "max_sent_len = max(len(s) for s in ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbaef9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a6769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4e092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb64432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['l'],\n",
       " ['l'],\n",
       " ['e'],\n",
       " ['g'],\n",
       " ['a'],\n",
       " ['d'],\n",
       " ['a'],\n",
       " ['sss'],\n",
       " ['sss'],\n",
       " ['sss'],\n",
       " ['sss'],\n",
       " ['sss'],\n",
       " ['sss'],\n",
       " ['sss']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4939300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeeede7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "mlds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
