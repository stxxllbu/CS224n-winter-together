{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190d9f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shaozhetao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import batch_iter\n",
    "from vocab import Vocab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a17545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path, source):\n",
    "    # Understood\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    @param source (str): \"tgt\" or \"src\" indicating whether text\n",
    "        is of the source language or target language\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = nltk.word_tokenize(line)\n",
    "        # only append <s> and </s> to the target sentence\n",
    "        if source == 'tgt':\n",
    "            sent = ['<s>'] + sent + ['</s>']\n",
    "        data.append(sent)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f30bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_SIZE = 3\n",
    "DROPOUT_RATE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38baae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed * 13 // 7)\n",
    "\n",
    "# Load training data & vocabulary\n",
    "train_data_src = read_corpus('./sanity_check_en_es_data/train_sanity_check.es', 'src')\n",
    "train_data_tgt = read_corpus('./sanity_check_en_es_data/train_sanity_check.en', 'tgt')\n",
    "train_data = list(zip(train_data_src, train_data_tgt))\n",
    "\n",
    "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    src_sents = src_sents\n",
    "    tgt_sents = tgt_sents\n",
    "    break\n",
    "vocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a630c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = './sanity_check_en_es_data/vocab_sanity_check.json'\n",
    "entry = json.load(open(file_path, 'r'))\n",
    "# src_word2id = entry['src_word2id']\n",
    "# tgt_word2id = entry['tgt_word2id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6190f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vocab.VocabEntry"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.src) # class of VocabEntry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c4d5ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Comencemos' in vocab.src.word2id\n",
    "vocab.src.word2id['por']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c546a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordids = [[vocab.src[w] for w in s] for s in src_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabd47ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 29, 3, 7, 12, 30, 3, 4, 8, 3, 3, 3, 8, 3, 15, 8, 3, 11, 6, 3, 3, 3],\n",
       " [3, 6, 3, 4, 3, 4, 3, 3, 3, 3, 9, 3, 3, 3],\n",
       " [3, 5, 47, 3, 6, 3, 3, 6, 3, 3],\n",
       " [3, 34, 20, 35, 24, 7, 8, 3, 3, 3],\n",
       " [3, 3, 3, 3, 3, 3]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9e3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.t(torch.tensor(pad_sents(wordids, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8a5f4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMT(\n",
    "        embed_size=EMBED_SIZE,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5fc051b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings): ModelEmbeddings(\n",
       "    (source): Embedding(77, 3, padding_idx=0)\n",
       "    (target): Embedding(85, 3, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e550b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lengths = [len(s) for s in src_sents]\n",
    "source_padded = model.vocab.src.to_input_tensor(src_sents, device='cpu') # (src_len, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c40036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 14, 10, 10, 6]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55f6332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 29,  3,  7, 12, 30,  3,  4,  8,  3,  3,  3,  8,  3, 15,  8,  3, 11,\n",
       "          6,  3,  3,  3],\n",
       "        [ 3,  6,  3,  4,  3,  4,  3,  3,  3,  3,  9,  3,  3,  3,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 3,  5, 47,  3,  6,  3,  3,  6,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 3, 34, 20, 35, 24,  7,  8,  3,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 3,  3,  3,  3,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d9bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embeddings = ModelEmbeddings(EMBED_SIZE, vocab)\n",
    "X = model_embeddings.source(source_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4840b44c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab373e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c969515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xz = pack_padded_sequence(X, torch.tensor(source_lengths)) #packed (src_len, b, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bb612535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0d1147c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e878fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.LSTM(input_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, bidirectional=True, bias=True)\n",
    "enc_hiddens, (last_hidden, last_cell) = encoder(Xz) #(src_len, b, h*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "63e3efd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d883dc49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d221fa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-1.8370e-02, -8.4587e-03,  1.5130e-01,  5.3777e-02,  2.7016e-01,\n",
       "         -2.1867e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01,  1.2228e-01,  2.7418e-01,\n",
       "         -4.2072e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01,  1.7103e-01,  2.6669e-01,\n",
       "         -1.9632e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01,  7.4291e-02,  2.7799e-01,\n",
       "         -1.5331e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01, -7.2549e-02,  2.4953e-01,\n",
       "         -6.9482e-02],\n",
       "        [-1.0473e-02,  1.4300e-01,  1.5000e-01,  1.8946e-01, -6.6002e-03,\n",
       "         -1.8303e-01],\n",
       "        [-2.8854e-02,  1.0664e-01, -3.0446e-02,  1.2274e-01,  1.1017e-01,\n",
       "         -1.7836e-01],\n",
       "        [ 1.6446e-02,  2.7651e-01,  1.6091e-01,  1.8394e-01, -6.2075e-02,\n",
       "         -1.5496e-01],\n",
       "        [-2.2691e-02,  1.4687e-01,  2.2541e-01,  2.7052e-01, -7.9282e-02,\n",
       "         -1.6494e-01],\n",
       "        [-2.7597e-02, -1.6700e-02,  2.0493e-01, -7.3162e-02,  2.5088e-01,\n",
       "         -6.3658e-02],\n",
       "        [-2.5007e-02,  4.0079e-02,  2.1535e-01,  1.0441e-01,  2.7313e-01,\n",
       "         -2.8405e-01],\n",
       "        [-3.0060e-02,  3.4990e-02,  1.2574e-01,  1.3144e-01,  2.7852e-01,\n",
       "         -4.1378e-01],\n",
       "        [ 1.3611e-01,  1.8130e-01, -4.5629e-04,  1.1931e-01,  1.3082e-01,\n",
       "         -1.1214e-01],\n",
       "        [ 1.4124e-01,  1.3728e-01,  4.8321e-02,  1.6431e-01,  1.4068e-01,\n",
       "         -8.9468e-02],\n",
       "        [-3.2959e-02, -2.1741e-02,  2.2412e-01, -7.3890e-02,  2.5273e-01,\n",
       "         -5.5931e-02],\n",
       "        [ 2.5603e-01,  2.3464e-01,  4.4941e-02,  1.2187e-01,  1.1519e-02,\n",
       "         -1.0077e-01],\n",
       "        [-1.3613e-01,  9.0909e-02, -8.4996e-02,  8.9477e-02,  1.1624e-01,\n",
       "         -1.5738e-01],\n",
       "        [ 1.5069e-02,  7.6954e-02,  1.4819e-01,  9.2920e-02,  2.7724e-01,\n",
       "         -3.2649e-01],\n",
       "        [ 1.1784e-01,  1.7846e-01,  1.2124e-02,  1.8616e-01,  2.0946e-02,\n",
       "         -8.9313e-02],\n",
       "        [-3.6184e-02, -2.4383e-02,  2.3110e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [ 3.8370e-02,  1.4667e-01,  1.2637e-01,  8.0541e-02,  2.9818e-01,\n",
       "         -2.6735e-01],\n",
       "        [-5.8646e-02,  2.9314e-02,  8.1887e-02,  9.7324e-02,  2.8069e-01,\n",
       "         -3.2328e-01],\n",
       "        [ 1.7253e-02,  1.3411e-01, -3.8686e-02,  1.1096e-01,  1.0675e-01,\n",
       "         -1.4394e-01],\n",
       "        [ 1.9003e-02,  2.0502e-01,  1.5308e-02,  1.9400e-01, -1.2149e-01,\n",
       "         -2.4427e-02],\n",
       "        [-3.8131e-02, -2.5677e-02,  2.3366e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [ 1.0518e-01,  1.3179e-01,  4.5991e-02,  1.3283e-01,  2.0425e-01,\n",
       "         -1.4380e-01],\n",
       "        [-1.8559e-01,  8.7400e-02, -9.3438e-02,  8.0330e-02,  1.0979e-01,\n",
       "         -1.2779e-01],\n",
       "        [-1.7826e-02,  4.8200e-02,  1.2094e-01, -2.7818e-03,  2.4575e-01,\n",
       "         -2.1955e-01],\n",
       "        [ 2.7406e-01,  2.4282e-01, -1.0667e-02,  1.1179e-01, -6.4418e-02,\n",
       "         -5.9799e-02],\n",
       "        [-3.9306e-02, -2.6290e-02,  2.3459e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [ 1.7987e-02,  4.9354e-02,  1.7952e-01,  1.0713e-01,  2.7324e-01,\n",
       "         -2.8919e-01],\n",
       "        [-7.1845e-02,  2.7549e-02,  7.2414e-02, -6.3932e-02,  2.4491e-01,\n",
       "         -1.0282e-01],\n",
       "        [-2.9320e-02,  7.6576e-03,  1.9156e-01,  7.8021e-02,  2.8314e-01,\n",
       "         -2.4945e-01],\n",
       "        [ 4.5831e-02,  1.7442e-01,  1.6359e-01,  6.6655e-02,  1.4457e-02,\n",
       "         -1.9775e-02],\n",
       "        [-3.9916e-02,  9.8214e-02, -7.4612e-02,  8.2574e-02,  5.2764e-02,\n",
       "         -1.1664e-01],\n",
       "        [-5.7984e-02,  2.6619e-04,  1.7366e-01, -5.5647e-02,  2.4873e-01,\n",
       "         -1.0690e-01],\n",
       "        [-4.9741e-02,  1.1207e-01, -1.8725e-02,  1.0514e-01,  1.1865e-01,\n",
       "         -1.1269e-01],\n",
       "        [ 2.1624e-04,  5.3282e-02,  2.0272e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [-4.5950e-02,  1.2071e-01,  1.1001e-01,  7.3045e-02,  8.2930e-03,\n",
       "         -4.8785e-02],\n",
       "        [-5.1041e-02, -1.4380e-02,  2.1137e-01, -3.4700e-02,  2.5962e-01,\n",
       "         -1.1121e-01],\n",
       "        [-3.6160e-02,  3.6519e-02,  1.3288e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-1.8247e-02,  7.0637e-03,  2.2106e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-4.0934e-02,  3.4451e-02,  1.8414e-01, -6.2940e-02,  2.5137e-01,\n",
       "         -8.3148e-02],\n",
       "        [-4.7193e-02, -2.1344e-02,  2.2565e-01,  2.1055e-02,  2.7645e-01,\n",
       "         -1.1276e-01],\n",
       "        [-3.9241e-02,  2.2948e-03,  1.9615e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [-2.8200e-02, -1.2640e-02,  2.2929e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [-4.2531e-02, -4.1606e-04,  2.1434e-01, -5.0036e-02,  2.5981e-01,\n",
       "         -8.0516e-02],\n",
       "        [ 6.4825e-02,  1.4966e-01,  1.2792e-01,  1.4430e-01, -2.6371e-02,\n",
       "         -6.9498e-02],\n",
       "        [-4.2665e-02, -1.5729e-02,  2.2643e-01, -1.4588e-02,  2.7732e-01,\n",
       "         -7.4129e-02],\n",
       "        [-2.4903e-03,  4.4563e-02,  2.2067e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [-6.0359e-02,  8.5429e-02,  2.7416e-01,  1.2700e-01,  3.8013e-02,\n",
       "         -7.5270e-02],\n",
       "        [-1.9531e-02,  2.7878e-03,  2.2901e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-4.6327e-02,  1.3555e-02,  2.4825e-01,  6.6762e-02,  2.6782e-01,\n",
       "         -1.0741e-01],\n",
       "        [-2.8854e-02, -1.4622e-02,  2.3239e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [ 1.2146e-01,  2.4179e-01,  1.6040e-01,  1.8048e-01, -1.4903e-01,\n",
       "         -7.0079e-02],\n",
       "        [ 5.2093e-03,  1.5579e-01,  2.7766e-01,  1.6799e-01,  3.8358e-02,\n",
       "         -1.5478e-01],\n",
       "        [-1.8295e-02,  4.2366e-02,  2.4783e-01,  1.5184e-01,  2.7118e-01,\n",
       "         -2.0152e-01],\n",
       "        [-6.6031e-02,  1.9060e-01,  1.4273e-01,  1.9093e-01, -2.6710e-02,\n",
       "         -1.5834e-01],\n",
       "        [-7.3503e-02,  1.5539e-01, -2.8999e-02,  1.0505e-01,  1.1663e-01,\n",
       "         -1.1493e-01],\n",
       "        [-4.4281e-02,  5.8046e-02,  1.2361e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [-4.4526e-02,  1.1818e-02,  1.9187e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-4.3948e-02, -1.0086e-02,  2.1785e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02]], grad_fn=<CatBackward>), batch_sizes=tensor([5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51413b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0439, -0.0101,  0.2179],\n",
       "         [-0.0289, -0.0146,  0.2324],\n",
       "         [-0.0392,  0.0023,  0.1961],\n",
       "         [-0.0282, -0.0126,  0.2293],\n",
       "         [-0.0393, -0.0263,  0.2346]],\n",
       "\n",
       "        [[ 0.0538,  0.2702, -0.2187],\n",
       "         [ 0.1223,  0.2742, -0.4207],\n",
       "         [ 0.1710,  0.2667, -0.1963],\n",
       "         [ 0.0743,  0.2780, -0.1533],\n",
       "         [-0.0725,  0.2495, -0.0695]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45358bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens, b = pad_packed_sequence(enc_hiddens, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6efde917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9d7c74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_masks = torch.zeros(enc_hiddens.size(0), enc_hiddens.size(1), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad88ec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 14, 10, 10, 6]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c33137a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22\n",
      "1 14\n",
      "2 10\n",
      "3 10\n",
      "4 6\n"
     ]
    }
   ],
   "source": [
    "for e_id, src_len in enumerate(source_lengths):\n",
    "    print (e_id, src_len)\n",
    "    enc_masks[e_id, src_len:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "33c1e57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d6f1672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b70ff600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa898400",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens_target = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "dec_init_state_target = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c67405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_target.shape #torch.Size([5, 22, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b14b4cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_init_state_target[1].shape #([5,3], [5,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9fd23",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bf8b6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7e1cf1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.tgt['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c0ca909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_masks=(target_padded != vocab.tgt['<pad>']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c39b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0118d96",
   "metadata": {},
   "source": [
    "## Question 1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "42cf0b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ec81a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = HIDDEN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0f2f580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_projection = nn.Linear(hidden_size*2, hidden_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "98c1f4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 3])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_projection(enc_hiddens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "187cd106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.1590,  0.6634, -0.2352],\n",
       "         [-0.2974, -0.6724,  0.8060],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.4922,  1.7666,  0.0404]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-1.4359,  0.7409, -1.6357],\n",
       "         [ 0.4461, -1.6570,  0.6247]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 2.9154, -0.1985,  0.7507],\n",
       "         [-1.2673, -0.1306, -0.3743],\n",
       "         [-0.3204,  1.5569, -1.4629]],\n",
       "\n",
       "        [[ 0.3047,  0.8214, -2.6705],\n",
       "         [-0.3204,  1.5569, -1.4629],\n",
       "         [-0.7392, -0.1709,  1.2120],\n",
       "         [-0.0135,  0.9174, -1.8431],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[ 1.3099, -1.3060, -1.4669],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.1783, -0.8092,  0.2455],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[-0.6697, -0.1985, -1.1560],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-0.6697, -0.1985, -1.1560],\n",
       "         [-0.3204,  1.5569, -1.4629],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [ 0.9814, -1.9638, -0.2218],\n",
       "         [ 0.4922,  1.7666,  0.0404]],\n",
       "\n",
       "        [[-0.4924, -0.7196,  0.3186],\n",
       "         [-0.7392, -0.1709,  1.2120],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-0.1235,  0.6418, -2.1429],\n",
       "         [ 0.4461, -1.6570,  0.6247]],\n",
       "\n",
       "        [[-0.3317, -0.4190, -1.4119],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.4531, -0.1112,  1.0307],\n",
       "         [-0.3204,  1.5569, -1.4629]],\n",
       "\n",
       "        [[-0.3204,  1.5569, -1.4629],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-0.6697, -0.1985, -1.1560],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[ 1.3579,  1.3583, -0.5818],\n",
       "         [ 1.9433, -1.7311, -1.2552],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.2382, -0.5245,  0.6758]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3424,  2.0673, -1.0484],\n",
       "         [ 0.2382, -0.5245,  0.6758],\n",
       "         [ 0.2382, -0.5245,  0.6758],\n",
       "         [ 0.2382, -0.5245,  0.6758],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.3579,  1.3583, -0.5818],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3204,  1.5569, -1.4629],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1182, -0.8322,  0.1364],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_embeddings.target(target_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641818ee",
   "metadata": {},
   "source": [
    "**target explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d4a76279",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "10cb2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_padded = target_padded[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7eae9366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63006fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 15, 15, 15, 13]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(t) for t in tgt_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d73abc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytgt = vocab.tgt.to_input_tensor(tgt_sents, device='cpu')\n",
    "# tgt_sents #english while src_sents is spanish\n",
    "# mytgt = target_padded\n",
    "# target_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bf52e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgt_sents[0] ['<s>', 'Let', \"'s'\", 'start', ...]\n",
    "\n",
    "#src_sents[0] ['Comencemos', 'por', 'pensar', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db27553",
   "metadata": {},
   "source": [
    "look back to target paddwed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ef02f56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bf82c8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = model_embeddings.target(target_padded)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "07d5efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.split(Y, 1, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a86b54b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cfa1dc8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926]]], grad_fn=<SplitBackward>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # this is embedding for <s> and you need learn embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "581e7e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(x[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cce530d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b8bca8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_state #(two tensor = dec_init_state)\n",
    "enc_hiddens.shape #torch.Size([5, 22, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9b2c0d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 3])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_proj.shape #torch.Size([5, 22, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "42b52aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens_proj = att_projection(enc_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8b5c14dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_masks.shape #torch.Size([5, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bb833551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ybar_t.shape  #torch.Size([5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "a3fe6faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_prev.shape # torch.Size([5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "38dbeb2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "062da830",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTER = [0]\n",
    "def stepFunction(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj, enc_masks):\n",
    "   dec_state = torch.load('./sanity_check_en_es_data/step_dec_state_{}.pkl'.format(COUNTER[0]))\n",
    "   o_t = torch.load('./sanity_check_en_es_data/step_o_t_{}.pkl'.format(COUNTER[0]))\n",
    "   COUNTER[0]+=1\n",
    "   return dec_state, o_t, None\n",
    "model.step = stepFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a8dc5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_prev = torch.zeros(5, 3, device='cpu')\n",
    "combined_outputs = []\n",
    "Y = model_embeddings.target(target_padded) # 23, 已经去掉最后一个</s>\n",
    "Y_ts = torch.split(Y, 1)\n",
    "for i in range(len(Y_ts)):\n",
    "#     print (i)\n",
    "    Y_t = Y_ts[i]\n",
    "    Y_t = torch.squeeze(Y_t)\n",
    "    Ybar_t = torch.cat((Y_t, o_prev), 1)\n",
    "    dec_state, o_t, _ = model.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj,\n",
    "                                                        enc_masks)\n",
    "#     o_prev = o_t\n",
    "    combined_outputs.append(o_t)\n",
    "    o_prev = o_t\n",
    "#     print (o_t.shape)\n",
    "combined_outputs = torch.stack(combined_outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "b4e56f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c0b039e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "3c7d8c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "251d62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_outputs consistent with combined_outputs_target from loading output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a809821",
   "metadata": {},
   "source": [
    "**loading output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "087eb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_init_state = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')\n",
    "enc_hiddens = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "enc_masks = torch.load('./sanity_check_en_es_data/enc_masks.pkl')\n",
    "target_padded = torch.load('./sanity_check_en_es_data/target_padded.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4ed0f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "569ace3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape #correct with tgt_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e133ce1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "combined_outputs_target = torch.load('./sanity_check_en_es_data/combined_outputs.pkl')\n",
    "print(combined_outputs_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3de04b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b74c560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = combined_outputs_target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2395910c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xx[0]) # 22*5*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d42ffb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_outputs_pred = model.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7eb05",
   "metadata": {},
   "source": [
    "## Question 1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "43e7e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_hidden=dec_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "b22b3806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5bff549c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unsqueeze_dec_hidden = dec_hidden.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "cad02cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 3])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "7ea9b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 1])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueeze_dec_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "172516f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_t = torch.bmm(enc_hiddens_proj, unsqueeze_dec_hidden).squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb614ae3",
   "metadata": {},
   "source": [
    "### part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "ebdda040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "09dee9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0530, -0.0624, -0.0673, -0.0699, -0.0711, -0.0717, -0.0720, -0.0721,\n",
       "         -0.0721, -0.0721, -0.0720, -0.0718, -0.0716, -0.0712, -0.0707, -0.0698,\n",
       "         -0.0685, -0.0665, -0.0633, -0.0585, -0.0515, -0.0423],\n",
       "        [-0.0518, -0.0610, -0.0658, -0.0681, -0.0691, -0.0693, -0.0691, -0.0684,\n",
       "         -0.0671, -0.0652, -0.0621, -0.0574, -0.0505, -0.0414,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0502, -0.0589, -0.0631, -0.0647, -0.0647, -0.0633, -0.0606, -0.0561,\n",
       "         -0.0493, -0.0405,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0502, -0.0589, -0.0631, -0.0647, -0.0647, -0.0633, -0.0606, -0.0561,\n",
       "         -0.0493, -0.0405,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0452, -0.0519, -0.0536, -0.0515, -0.0462, -0.0383,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8dcda4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_t = F.softmax(e_t, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "2e377c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 22])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_t.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4fad5be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "7ad0d76b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_t = torch.bmm(alpha_t.unsqueeze(1), enc_hiddens).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "dc3377aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f9d83d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_t = torch.cat((a_t, dec_hidden), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "44cefe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbed67f",
   "metadata": {},
   "source": [
    "### Final exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "8b6899fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_outputs.shape # target_padded 从0开始，删掉的是</s>,共23个； \n",
    "#combined_outputs 存的是o_1, ..., o_t; o_0是0， o_1是target_padded 0 (<s>)算出来的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "266f1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_bar0 = np.concat(0, <s>) -> o_1（prefix 0） 是第一个word的prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "69332f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab_projection = nn.Linear(HIDDEN_SIZE, len(vocab.tgt), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "3406f8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 85])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab_projection(combined_outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8d748b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-377.7800, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(target_vocab_projection(combined_outputs), dim=-1)[0][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "cca8b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = F.log_softmax(target_vocab_projection(combined_outputs), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "7ebdff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "e91de005",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_masks = (target_padded != vocab.tgt['<pad>']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "4ab9518e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# target_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "1388c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_padded[1:].unsqueeze(-1) #(22,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "9bf6fc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  1,  1,  1],\n",
       "        [ 3, 55, 67,  3, 73],\n",
       "        [ 3,  4,  3, 50, 74],\n",
       "        [ 3,  3,  7, 51,  5],\n",
       "        [46,  5, 14, 36,  3],\n",
       "        [70,  3, 68,  3,  3],\n",
       "        [22,  3, 22,  5,  3],\n",
       "        [ 4,  3,  4, 11, 73],\n",
       "        [66, 14,  3, 35, 74],\n",
       "        [71,  3,  3,  9,  5],\n",
       "        [ 5,  3, 22,  4,  3],\n",
       "        [ 4, 39,  4,  3,  3],\n",
       "        [ 3,  3,  3,  3,  2],\n",
       "        [ 3,  3,  3,  3,  0],\n",
       "        [72,  2,  2,  2,  0],\n",
       "        [ 4,  0,  0,  0,  0],\n",
       "        [ 3,  0,  0,  0,  0],\n",
       "        [ 5,  0,  0,  0,  0],\n",
       "        [ 3,  0,  0,  0,  0],\n",
       "        [ 3,  0,  0,  0,  0],\n",
       "        [ 8,  0,  0,  0,  0],\n",
       "        [ 3,  0,  0,  0,  0],\n",
       "        [ 3,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "b89e2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = torch.gather(P, index=target_padded[1:].unsqueeze(-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "67cd2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P[22][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "7f7978de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4097, -4.4879, -4.4394, -4.4152, -4.3741],\n",
       "        [-4.4284, -4.4335, -4.4332, -4.4152, -4.4437],\n",
       "        [-4.4345, -4.4368, -4.4490, -4.4480, -4.4486],\n",
       "        [-4.4566, -4.4321, -4.4417, -4.4418, -4.4470],\n",
       "        [-4.4449, -4.4413, -4.4429, -4.4436, -4.4485],\n",
       "        [-4.4528, -4.4422, -4.4353, -4.4493, -4.4494],\n",
       "        [-4.4411, -4.4428, -4.4446, -4.4378, -4.4662],\n",
       "        [-4.4425, -4.4435, -4.4455, -4.4368, -4.4408],\n",
       "        [-4.4433, -4.4434, -4.4457, -4.4354, -4.4699],\n",
       "        [-4.4383, -4.4436, -4.4303, -4.4452, -4.4506],\n",
       "        [-4.4418, -4.4422, -4.4452, -4.4460, -4.4507],\n",
       "        [-4.4416, -4.4437, -4.4461, -4.4461, -4.4599],\n",
       "        [-4.4416, -4.4438, -4.4461, -4.4461, -4.4410],\n",
       "        [-4.4413, -4.4451, -4.4500, -4.4500, -4.4410],\n",
       "        [-4.4419, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4417, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4393, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4417, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4417, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4442, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4417, -4.4424, -4.4419, -4.4419, -4.4410],\n",
       "        [-4.4417, -4.4424, -4.4419, -4.4419, -4.4410]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "029f8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver = torch.gather(P, index=target_padded[:-1].unsqueeze(-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "4d999385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.4879, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0][1][55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "d1437426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silver.squeeze(-1)*target_masks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "6159a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.squeeze(-1)*target_masks[1:]\n",
    "scores = target_gold_words_log_prob.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "1bf3de59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-97.6923, -62.2219, -62.1951, -62.1563, -53.3496],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "1abbf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gold_words_log_prob \n",
    "= torch.gather(P, index=target_padded[1:].unsqueeze(-1), dim=-1).squeeze(-1) * target_masks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "456d8278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_gold_words_log_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "08820014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 85])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P.gather(index=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "c7afdc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4097, -4.4879, -4.4394, -4.4152, -4.3741],\n",
       "        [-4.4284, -4.4335, -4.4332, -4.4152, -4.4437],\n",
       "        [-4.4345, -4.4368, -4.4490, -4.4480, -4.4486],\n",
       "        [-4.4566, -4.4321, -4.4417, -4.4418, -4.4470],\n",
       "        [-4.4449, -4.4413, -4.4429, -4.4436, -4.4485],\n",
       "        [-4.4528, -4.4422, -4.4353, -4.4493, -4.4494],\n",
       "        [-4.4411, -4.4428, -4.4446, -4.4378, -4.4662],\n",
       "        [-4.4425, -4.4435, -4.4455, -4.4368, -4.4408],\n",
       "        [-4.4433, -4.4434, -4.4457, -4.4354, -4.4699],\n",
       "        [-4.4383, -4.4436, -4.4303, -4.4452, -4.4506],\n",
       "        [-4.4418, -4.4422, -4.4452, -4.4460, -4.4507],\n",
       "        [-4.4416, -4.4437, -4.4461, -4.4461, -4.4599],\n",
       "        [-4.4416, -4.4438, -4.4461, -4.4461, -0.0000],\n",
       "        [-4.4413, -4.4451, -4.4500, -4.4500, -0.0000],\n",
       "        [-4.4419, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4417, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4393, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4417, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4417, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4442, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4417, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-4.4417, -0.0000, -0.0000, -0.0000, -0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_gold_words_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574dbc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97940bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "018325c4",
   "metadata": {},
   "source": [
    "**understand gather function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "de452be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.arange(40).reshape(4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "93c72220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2b7c25c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "bddccb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.LongTensor([3,7,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "7e295989",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = indices.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c86c6825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [7],\n",
       "        [4],\n",
       "        [1]])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "7ee981b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [17],\n",
       "        [24],\n",
       "        [31]])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.gather(dim=1, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "f522c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "max_seq_len = 9\n",
    "hidden_size = 6\n",
    "x = torch.empty(batch_size, max_seq_len, hidden_size)\n",
    "for i in range(batch_size):\n",
    "  for j in range(max_seq_len):\n",
    "    for k in range(hidden_size):\n",
    "      x[i,j,k] = i*100 + j*10 + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "3a71f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = torch.LongTensor([5,6,1,8,3,7,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "f0b21af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = lens.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "42eebd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5],\n",
       "        [6],\n",
       "        [1],\n",
       "        [8],\n",
       "        [3],\n",
       "        [7],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "1e4abd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = lens.repeat(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "a7e9c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = indices.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "809286ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 5]],\n",
       "\n",
       "        [[6, 6]],\n",
       "\n",
       "        [[1, 1]],\n",
       "\n",
       "        [[8, 8]],\n",
       "\n",
       "        [[3, 3]],\n",
       "\n",
       "        [[7, 7]],\n",
       "\n",
       "        [[3, 3]],\n",
       "\n",
       "        [[4, 4]]])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "34c53782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = torch.gather(x, 1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "2caa3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "ea096cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[:,6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "faecf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13faf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize_layers(model):\n",
    "    \"\"\" Reinitialize the Layer Weights for Sanity Checks.\n",
    "    \"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(0.3)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.1)\n",
    "        elif type(m) == nn.Embedding:\n",
    "            m.weight.data.fill_(0.15)\n",
    "        elif type(m) == nn.Dropout:\n",
    "            nn.Dropout(DROPOUT_RATE)\n",
    "    with torch.no_grad():\n",
    "        model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c355824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a53d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b22931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f3329a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Set, Union\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, vocab):\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # default values\n",
    "        self.source = None\n",
    "        self.target = None\n",
    "\n",
    "        src_pad_token_idx = vocab.src['<pad>']\n",
    "        tgt_pad_token_idx = vocab.tgt['<pad>']\n",
    "\n",
    "        self.source = nn.Embedding(len(vocab.src), embed_size, src_pad_token_idx)\n",
    "        self.target = nn.Embedding(len(vocab.tgt), embed_size, tgt_pad_token_idx)\n",
    "\n",
    "class NMT(nn.Module):\n",
    "    \"\"\" Simple Neural Machine Translation Model:\n",
    "        - Bidrectional LSTM Encoder\n",
    "        - Unidirection LSTM Decoder\n",
    "        - Global Attention Model (Luong, et al. 2015)\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, hidden_size, vocab, dropout_rate=0.2):\n",
    "        super(NMT, self).__init__()\n",
    "        self.model_embeddings = ModelEmbeddings(embed_size, vocab)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.vocab = vocab\n",
    "\n",
    "        # default values\n",
    "        self.encoder = None \n",
    "        self.decoder = None\n",
    "        self.h_projection = None\n",
    "        self.c_projection = None\n",
    "        self.att_projection = None\n",
    "        self.combined_output_projection = None\n",
    "        self.target_vocab_projection = None\n",
    "        self.dropout = None\n",
    "        # For sanity check only, not relevant to implementation\n",
    "        self.gen_sanity_check = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def decode(self, enc_hiddens: torch.Tensor, enc_masks: torch.Tensor,\n",
    "                dec_init_state: Tuple[torch.Tensor, torch.Tensor], target_padded: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute combined output vectors for a batch.\n",
    "\n",
    "        @param enc_hiddens (Tensor): Hidden states (b, src_len, h*2), where\n",
    "                                     b = batch size, src_len = maximum source sentence length, h = hidden size.\n",
    "        @param enc_masks (Tensor): Tensor of sentence masks (b, src_len), where\n",
    "                                     b = batch size, src_len = maximum source sentence length.\n",
    "        @param dec_init_state (tuple(Tensor, Tensor)): Initial state and cell for decoder\n",
    "        @param target_padded (Tensor): Gold-standard padded target sentences (tgt_len, b), where\n",
    "                                       tgt_len = maximum target sentence length, b = batch size. \n",
    "\n",
    "        @returns combined_outputs (Tensor): combined output tensor  (tgt_len, b,  h), where\n",
    "                                        tgt_len = maximum target sentence length, b = batch_size,  h = hidden size\n",
    "        \"\"\"\n",
    "        # Chop of the <END> token for max length sentences.\n",
    "        target_padded = target_padded[:-1]\n",
    "\n",
    "        # Initialize the decoder state (hidden and cell)\n",
    "        dec_state = dec_init_state\n",
    "\n",
    "        # Initialize previous combined output vector o_{t-1} as zero\n",
    "        batch_size = enc_hiddens.size(0)\n",
    "        o_prev = torch.zeros(batch_size, self.hidden_size, device='cpu')\n",
    "\n",
    "        # Initialize a list we will use to collect the combined output o_t on each step\n",
    "        combined_outputs = []\n",
    "\n",
    "        enc_hiddens_proj = self.att_projection(enc_hiddens)\n",
    "        Y = self.model_embeddings.target(target_padded)\n",
    "        Y_ts = torch.split(Y, 1)\n",
    "        for Y_t in Y_ts:\n",
    "            Y_t = torch.squeeze(Y_t)\n",
    "            Ybar_t = torch.cat((Y_t, o_prev), 1)\n",
    "            dec_state, o_t, _ = self.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj,\n",
    "                                                        enc_masks)\n",
    "            combined_outputs.append(o_t.tolist())\n",
    "            o_prev = o_t\n",
    "        combined_outputs = torch.stack(combined_outputs, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca86c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61b609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3321270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bec98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2indices(sents):\n",
    "    \"\"\" Convert list of words or list of sentences of words\n",
    "    into list or list of list of indices.\n",
    "    @param sents (list[str] or list[list[str]]): sentence(s) in words\n",
    "    @return word_ids (list[int] or list[list[int]]): sentence(s) in indices\n",
    "    \"\"\"\n",
    "    if type(sents[0]) == list:\n",
    "        return [[[w] for w in s] for s in sents]\n",
    "    else:\n",
    "        return [[w] for w in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a9072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "af4453f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "da98b046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 5, 3]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.gather(0, torch.tensor([[2,1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "51af885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings): ModelEmbeddings(\n",
       "    (source): Embedding(77, 3, padding_idx=0)\n",
       "    (target): Embedding(85, 3, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "28dea08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings): ModelEmbeddings(\n",
       "    (source): Embedding(77, 3, padding_idx=0)\n",
       "    (target): Embedding(85, 3, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8cbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "mlds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
