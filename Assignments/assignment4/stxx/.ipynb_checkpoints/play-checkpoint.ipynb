{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190d9f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shaozhetao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import batch_iter\n",
    "from vocab import Vocab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a17545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path, source):\n",
    "    # Understood\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    @param source (str): \"tgt\" or \"src\" indicating whether text\n",
    "        is of the source language or target language\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = nltk.word_tokenize(line)\n",
    "        # only append <s> and </s> to the target sentence\n",
    "        if source == 'tgt':\n",
    "            sent = ['<s>'] + sent + ['</s>']\n",
    "        data.append(sent)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f30bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_SIZE = 3\n",
    "DROPOUT_RATE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38baae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed * 13 // 7)\n",
    "\n",
    "# Load training data & vocabulary\n",
    "train_data_src = read_corpus('./sanity_check_en_es_data/train_sanity_check.es', 'src')\n",
    "train_data_tgt = read_corpus('./sanity_check_en_es_data/train_sanity_check.en', 'tgt')\n",
    "train_data = list(zip(train_data_src, train_data_tgt))\n",
    "\n",
    "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    src_sents = src_sents\n",
    "    tgt_sents = tgt_sents\n",
    "    break\n",
    "vocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a630c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = './sanity_check_en_es_data/vocab_sanity_check.json'\n",
    "entry = json.load(open(file_path, 'r'))\n",
    "# src_word2id = entry['src_word2id']\n",
    "# tgt_word2id = entry['tgt_word2id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6190f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vocab.VocabEntry"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.src) # class of VocabEntry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c4d5ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Comencemos' in vocab.src.word2id\n",
    "vocab.src.word2id['por']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c546a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordids = [[vocab.src[w] for w in s] for s in src_sents  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabd47ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 29, 3, 7, 12, 30, 3, 4, 8, 3, 3, 3, 8, 3, 15, 8, 3, 11, 6, 3, 3, 3],\n",
       " [3, 6, 3, 4, 3, 4, 3, 3, 3, 3, 9, 3, 3, 3],\n",
       " [3, 5, 47, 3, 6, 3, 3, 6, 3, 3],\n",
       " [3, 34, 20, 35, 24, 7, 8, 3, 3, 3],\n",
       " [3, 3, 3, 3, 3, 3]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9e3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.t(torch.tensor(pad_sents(wordids, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8a5f4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMT(\n",
    "        embed_size=EMBED_SIZE,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5fc051b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings): ModelEmbeddings(\n",
       "    (source): Embedding(77, 3, padding_idx=0)\n",
       "    (target): Embedding(85, 3, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e550b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lengths = [len(s) for s in src_sents]\n",
    "source_padded = model.vocab.src.to_input_tensor(src_sents, device='cpu') # (src_len, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c40036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 14, 10, 10, 6]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55f6332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 29,  3,  7, 12, 30,  3,  4,  8,  3,  3,  3,  8,  3, 15,  8,  3, 11,\n",
       "          6,  3,  3,  3],\n",
       "        [ 3,  6,  3,  4,  3,  4,  3,  3,  3,  3,  9,  3,  3,  3,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 3,  5, 47,  3,  6,  3,  3,  6,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 3, 34, 20, 35, 24,  7,  8,  3,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 3,  3,  3,  3,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d9bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embeddings = ModelEmbeddings(EMBED_SIZE, vocab)\n",
    "X = model_embeddings.source(source_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4840b44c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab373e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c969515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xz = pack_padded_sequence(X, torch.tensor(source_lengths)) #packed (src_len, b, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a244d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "97894180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e878fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.LSTM(input_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, bidirectional=True, bias=True)\n",
    "enc_hiddens, (last_hidden, last_cell) = encoder(Xz) #(src_len, b, h*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c70000b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0130366e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8892ef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-1.8370e-02, -8.4587e-03,  1.5130e-01,  5.3777e-02,  2.7016e-01,\n",
       "         -2.1867e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01,  1.2228e-01,  2.7418e-01,\n",
       "         -4.2072e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01,  1.7103e-01,  2.6669e-01,\n",
       "         -1.9632e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01,  7.4291e-02,  2.7799e-01,\n",
       "         -1.5331e-01],\n",
       "        [-1.8370e-02, -8.4587e-03,  1.5130e-01, -7.2549e-02,  2.4953e-01,\n",
       "         -6.9482e-02],\n",
       "        [-1.0473e-02,  1.4300e-01,  1.5000e-01,  1.8946e-01, -6.6002e-03,\n",
       "         -1.8303e-01],\n",
       "        [-2.8854e-02,  1.0664e-01, -3.0446e-02,  1.2274e-01,  1.1017e-01,\n",
       "         -1.7836e-01],\n",
       "        [ 1.6446e-02,  2.7651e-01,  1.6091e-01,  1.8394e-01, -6.2075e-02,\n",
       "         -1.5496e-01],\n",
       "        [-2.2691e-02,  1.4687e-01,  2.2541e-01,  2.7052e-01, -7.9282e-02,\n",
       "         -1.6494e-01],\n",
       "        [-2.7597e-02, -1.6700e-02,  2.0493e-01, -7.3162e-02,  2.5088e-01,\n",
       "         -6.3658e-02],\n",
       "        [-2.5007e-02,  4.0079e-02,  2.1535e-01,  1.0441e-01,  2.7313e-01,\n",
       "         -2.8405e-01],\n",
       "        [-3.0060e-02,  3.4990e-02,  1.2574e-01,  1.3144e-01,  2.7852e-01,\n",
       "         -4.1378e-01],\n",
       "        [ 1.3611e-01,  1.8130e-01, -4.5629e-04,  1.1931e-01,  1.3082e-01,\n",
       "         -1.1214e-01],\n",
       "        [ 1.4124e-01,  1.3728e-01,  4.8321e-02,  1.6431e-01,  1.4068e-01,\n",
       "         -8.9468e-02],\n",
       "        [-3.2959e-02, -2.1741e-02,  2.2412e-01, -7.3890e-02,  2.5273e-01,\n",
       "         -5.5931e-02],\n",
       "        [ 2.5603e-01,  2.3464e-01,  4.4941e-02,  1.2187e-01,  1.1519e-02,\n",
       "         -1.0077e-01],\n",
       "        [-1.3613e-01,  9.0909e-02, -8.4996e-02,  8.9477e-02,  1.1624e-01,\n",
       "         -1.5738e-01],\n",
       "        [ 1.5069e-02,  7.6954e-02,  1.4819e-01,  9.2920e-02,  2.7724e-01,\n",
       "         -3.2649e-01],\n",
       "        [ 1.1784e-01,  1.7846e-01,  1.2124e-02,  1.8616e-01,  2.0946e-02,\n",
       "         -8.9313e-02],\n",
       "        [-3.6184e-02, -2.4383e-02,  2.3110e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [ 3.8370e-02,  1.4667e-01,  1.2637e-01,  8.0541e-02,  2.9818e-01,\n",
       "         -2.6735e-01],\n",
       "        [-5.8646e-02,  2.9314e-02,  8.1887e-02,  9.7324e-02,  2.8069e-01,\n",
       "         -3.2328e-01],\n",
       "        [ 1.7253e-02,  1.3411e-01, -3.8686e-02,  1.1096e-01,  1.0675e-01,\n",
       "         -1.4394e-01],\n",
       "        [ 1.9003e-02,  2.0502e-01,  1.5308e-02,  1.9400e-01, -1.2149e-01,\n",
       "         -2.4427e-02],\n",
       "        [-3.8131e-02, -2.5677e-02,  2.3366e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [ 1.0518e-01,  1.3179e-01,  4.5991e-02,  1.3283e-01,  2.0425e-01,\n",
       "         -1.4380e-01],\n",
       "        [-1.8559e-01,  8.7400e-02, -9.3438e-02,  8.0330e-02,  1.0979e-01,\n",
       "         -1.2779e-01],\n",
       "        [-1.7826e-02,  4.8200e-02,  1.2094e-01, -2.7818e-03,  2.4575e-01,\n",
       "         -2.1955e-01],\n",
       "        [ 2.7406e-01,  2.4282e-01, -1.0667e-02,  1.1179e-01, -6.4418e-02,\n",
       "         -5.9799e-02],\n",
       "        [-3.9306e-02, -2.6290e-02,  2.3459e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [ 1.7987e-02,  4.9354e-02,  1.7952e-01,  1.0713e-01,  2.7324e-01,\n",
       "         -2.8919e-01],\n",
       "        [-7.1845e-02,  2.7549e-02,  7.2414e-02, -6.3932e-02,  2.4491e-01,\n",
       "         -1.0282e-01],\n",
       "        [-2.9320e-02,  7.6576e-03,  1.9156e-01,  7.8021e-02,  2.8314e-01,\n",
       "         -2.4945e-01],\n",
       "        [ 4.5831e-02,  1.7442e-01,  1.6359e-01,  6.6655e-02,  1.4457e-02,\n",
       "         -1.9775e-02],\n",
       "        [-3.9916e-02,  9.8214e-02, -7.4612e-02,  8.2574e-02,  5.2764e-02,\n",
       "         -1.1664e-01],\n",
       "        [-5.7984e-02,  2.6619e-04,  1.7366e-01, -5.5647e-02,  2.4873e-01,\n",
       "         -1.0690e-01],\n",
       "        [-4.9741e-02,  1.1207e-01, -1.8725e-02,  1.0514e-01,  1.1865e-01,\n",
       "         -1.1269e-01],\n",
       "        [ 2.1624e-04,  5.3282e-02,  2.0272e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [-4.5950e-02,  1.2071e-01,  1.1001e-01,  7.3045e-02,  8.2930e-03,\n",
       "         -4.8785e-02],\n",
       "        [-5.1041e-02, -1.4380e-02,  2.1137e-01, -3.4700e-02,  2.5962e-01,\n",
       "         -1.1121e-01],\n",
       "        [-3.6160e-02,  3.6519e-02,  1.3288e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-1.8247e-02,  7.0637e-03,  2.2106e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-4.0934e-02,  3.4451e-02,  1.8414e-01, -6.2940e-02,  2.5137e-01,\n",
       "         -8.3148e-02],\n",
       "        [-4.7193e-02, -2.1344e-02,  2.2565e-01,  2.1055e-02,  2.7645e-01,\n",
       "         -1.1276e-01],\n",
       "        [-3.9241e-02,  2.2948e-03,  1.9615e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [-2.8200e-02, -1.2640e-02,  2.2929e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [-4.2531e-02, -4.1606e-04,  2.1434e-01, -5.0036e-02,  2.5981e-01,\n",
       "         -8.0516e-02],\n",
       "        [ 6.4825e-02,  1.4966e-01,  1.2792e-01,  1.4430e-01, -2.6371e-02,\n",
       "         -6.9498e-02],\n",
       "        [-4.2665e-02, -1.5729e-02,  2.2643e-01, -1.4588e-02,  2.7732e-01,\n",
       "         -7.4129e-02],\n",
       "        [-2.4903e-03,  4.4563e-02,  2.2067e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [-6.0359e-02,  8.5429e-02,  2.7416e-01,  1.2700e-01,  3.8013e-02,\n",
       "         -7.5270e-02],\n",
       "        [-1.9531e-02,  2.7878e-03,  2.2901e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-4.6327e-02,  1.3555e-02,  2.4825e-01,  6.6762e-02,  2.6782e-01,\n",
       "         -1.0741e-01],\n",
       "        [-2.8854e-02, -1.4622e-02,  2.3239e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02],\n",
       "        [ 1.2146e-01,  2.4179e-01,  1.6040e-01,  1.8048e-01, -1.4903e-01,\n",
       "         -7.0079e-02],\n",
       "        [ 5.2093e-03,  1.5579e-01,  2.7766e-01,  1.6799e-01,  3.8358e-02,\n",
       "         -1.5478e-01],\n",
       "        [-1.8295e-02,  4.2366e-02,  2.4783e-01,  1.5184e-01,  2.7118e-01,\n",
       "         -2.0152e-01],\n",
       "        [-6.6031e-02,  1.9060e-01,  1.4273e-01,  1.9093e-01, -2.6710e-02,\n",
       "         -1.5834e-01],\n",
       "        [-7.3503e-02,  1.5539e-01, -2.8999e-02,  1.0505e-01,  1.1663e-01,\n",
       "         -1.1493e-01],\n",
       "        [-4.4281e-02,  5.8046e-02,  1.2361e-01, -7.4635e-02,  2.5533e-01,\n",
       "         -4.5647e-02],\n",
       "        [-4.4526e-02,  1.1818e-02,  1.9187e-01, -7.5029e-02,  2.5911e-01,\n",
       "         -3.1903e-02],\n",
       "        [-4.3948e-02, -1.0086e-02,  2.1785e-01, -7.2703e-02,  2.6747e-01,\n",
       "         -1.3009e-02]], grad_fn=<CatBackward>), batch_sizes=tensor([5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc055a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0439, -0.0101,  0.2179],\n",
       "         [-0.0289, -0.0146,  0.2324],\n",
       "         [-0.0392,  0.0023,  0.1961],\n",
       "         [-0.0282, -0.0126,  0.2293],\n",
       "         [-0.0393, -0.0263,  0.2346]],\n",
       "\n",
       "        [[ 0.0538,  0.2702, -0.2187],\n",
       "         [ 0.1223,  0.2742, -0.4207],\n",
       "         [ 0.1710,  0.2667, -0.1963],\n",
       "         [ 0.0743,  0.2780, -0.1533],\n",
       "         [-0.0725,  0.2495, -0.0695]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45358bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens, b = pad_packed_sequence(enc_hiddens, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df1356e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05c4bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_masks = torch.zeros(enc_hiddens.size(0), enc_hiddens.size(1), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83f547dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 14, 10, 10, 6]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8631fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22\n",
      "1 14\n",
      "2 10\n",
      "3 10\n",
      "4 6\n"
     ]
    }
   ],
   "source": [
    "for e_id, src_len in enumerate(source_lengths):\n",
    "    print (e_id, src_len)\n",
    "    enc_masks[e_id, src_len:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7bc90571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d6f1672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b70ff600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 5, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa898400",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens_target = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "dec_init_state_target = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c67405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_target.shape #torch.Size([5, 22, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b14b4cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_init_state_target[1].shape #([5,3], [5,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19c2ea",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "950be262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8e71939e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.tgt['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7c0c986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_masks=(target_padded != vocab.tgt['<pad>']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c4e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284e3087",
   "metadata": {},
   "source": [
    "## Question 1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "353dc7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "81edf571",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = HIDDEN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2c6d239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_projection = nn.Linear(hidden_size*2, hidden_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "15866c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 3])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_projection(enc_hiddens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0486b88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.1590,  0.6634, -0.2352],\n",
       "         [-0.2974, -0.6724,  0.8060],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.4922,  1.7666,  0.0404]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-1.4359,  0.7409, -1.6357],\n",
       "         [ 0.4461, -1.6570,  0.6247]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 2.9154, -0.1985,  0.7507],\n",
       "         [-1.2673, -0.1306, -0.3743],\n",
       "         [-0.3204,  1.5569, -1.4629]],\n",
       "\n",
       "        [[ 0.3047,  0.8214, -2.6705],\n",
       "         [-0.3204,  1.5569, -1.4629],\n",
       "         [-0.7392, -0.1709,  1.2120],\n",
       "         [-0.0135,  0.9174, -1.8431],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[ 1.3099, -1.3060, -1.4669],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.1783, -0.8092,  0.2455],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[-0.6697, -0.1985, -1.1560],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-0.6697, -0.1985, -1.1560],\n",
       "         [-0.3204,  1.5569, -1.4629],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [ 0.9814, -1.9638, -0.2218],\n",
       "         [ 0.4922,  1.7666,  0.0404]],\n",
       "\n",
       "        [[-0.4924, -0.7196,  0.3186],\n",
       "         [-0.7392, -0.1709,  1.2120],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-0.1235,  0.6418, -2.1429],\n",
       "         [ 0.4461, -1.6570,  0.6247]],\n",
       "\n",
       "        [[-0.3317, -0.4190, -1.4119],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.4531, -0.1112,  1.0307],\n",
       "         [-0.3204,  1.5569, -1.4629]],\n",
       "\n",
       "        [[-0.3204,  1.5569, -1.4629],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-0.6697, -0.1985, -1.1560],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[ 1.3579,  1.3583, -0.5818],\n",
       "         [ 1.9433, -1.7311, -1.2552],\n",
       "         [ 1.3579,  1.3583, -0.5818],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.2382, -0.5245,  0.6758]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3424,  2.0673, -1.0484],\n",
       "         [ 0.2382, -0.5245,  0.6758],\n",
       "         [ 0.2382, -0.5245,  0.6758],\n",
       "         [ 0.2382, -0.5245,  0.6758],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.3579,  1.3583, -0.5818],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3204,  1.5569, -1.4629],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1182, -0.8322,  0.1364],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.0323, -0.3952,  0.7286],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_embeddings.target(target_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c851803",
   "metadata": {},
   "source": [
    "**target explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7818ca91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b3bc262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_padded = target_padded[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "126022bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "edb6b3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 15, 15, 15, 13]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(t) for t in tgt_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84d3daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytgt = vocab.tgt.to_input_tensor(tgt_sents, device='cpu')\n",
    "# tgt_sents #english while src_sents is spanish\n",
    "# mytgt = target_padded\n",
    "# target_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c379b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgt_sents[0] ['<s>', 'Let', \"'s'\", 'start', ...]\n",
    "\n",
    "#src_sents[0] ['Comencemos', 'por', 'pensar', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298b296",
   "metadata": {},
   "source": [
    "look back to target paddwed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "27c61752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "05e2a2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = model_embeddings.target(target_padded)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "85581441",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.split(Y, 1, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e3c9c20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "de09ebcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926],\n",
       "         [-0.3120,  2.4534,  0.7926]]], grad_fn=<SplitBackward>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # this is embedding for <s> and you need learn embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "12311b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(x[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4693cd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "97155a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_state #(two tensor = dec_init_state)\n",
    "enc_hiddens.shape #torch.Size([5, 22, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5b361f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 3])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_proj.shape #torch.Size([5, 22, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8fe47a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens_proj = att_projection(enc_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9a1f0450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_masks.shape #torch.Size([5, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "02ccd0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ybar_t.shape  #torch.Size([5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ad4bcb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_prev.shape # torch.Size([5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3aad2a1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "92752655",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTER = [0]\n",
    "def stepFunction(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj, enc_masks):\n",
    "   dec_state = torch.load('./sanity_check_en_es_data/step_dec_state_{}.pkl'.format(COUNTER[0]))\n",
    "   o_t = torch.load('./sanity_check_en_es_data/step_o_t_{}.pkl'.format(COUNTER[0]))\n",
    "   COUNTER[0]+=1\n",
    "   return dec_state, o_t, None\n",
    "model.step = stepFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d60a2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_prev = torch.zeros(5, 3, device='cpu')\n",
    "combined_outputs = []\n",
    "Y = model_embeddings.target(target_padded) # 23, 已经去掉最后一个</s>\n",
    "Y_ts = torch.split(Y, 1)\n",
    "for i in range(len(Y_ts)):\n",
    "#     print (i)\n",
    "    Y_t = Y_ts[i]\n",
    "    Y_t = torch.squeeze(Y_t)\n",
    "    Ybar_t = torch.cat((Y_t, o_prev), 1)\n",
    "    dec_state, o_t, _ = model.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj,\n",
    "                                                        enc_masks)\n",
    "#     o_prev = o_t\n",
    "    combined_outputs.append(o_t)\n",
    "    o_prev = o_t\n",
    "#     print (o_t.shape)\n",
    "combined_outputs = torch.stack(combined_outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3f5f1fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 5, 3])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "e5e8c745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "3ef1d653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6e43c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_outputs consistent with combined_outputs_target from loading output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc011d",
   "metadata": {},
   "source": [
    "**loading output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "087eb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_init_state = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')\n",
    "enc_hiddens = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "enc_masks = torch.load('./sanity_check_en_es_data/enc_masks.pkl')\n",
    "target_padded = torch.load('./sanity_check_en_es_data/target_padded.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5898ffe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ddccb53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded.shape #correct with tgt_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "035747c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "combined_outputs_target = torch.load('./sanity_check_en_es_data/combined_outputs.pkl')\n",
    "print(combined_outputs_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "24f2a8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 6])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ae1ddceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = combined_outputs_target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "82b88a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xx[0]) # 22*5*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7336ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_outputs_pred = model.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2d002",
   "metadata": {},
   "source": [
    "## Question 1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75caa996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a066d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff549c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13faf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize_layers(model):\n",
    "    \"\"\" Reinitialize the Layer Weights for Sanity Checks.\n",
    "    \"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(0.3)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.1)\n",
    "        elif type(m) == nn.Embedding:\n",
    "            m.weight.data.fill_(0.15)\n",
    "        elif type(m) == nn.Dropout:\n",
    "            nn.Dropout(DROPOUT_RATE)\n",
    "    with torch.no_grad():\n",
    "        model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c355824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a53d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b22931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f3329a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Set, Union\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, vocab):\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # default values\n",
    "        self.source = None\n",
    "        self.target = None\n",
    "\n",
    "        src_pad_token_idx = vocab.src['<pad>']\n",
    "        tgt_pad_token_idx = vocab.tgt['<pad>']\n",
    "\n",
    "        self.source = nn.Embedding(len(vocab.src), embed_size, src_pad_token_idx)\n",
    "        self.target = nn.Embedding(len(vocab.tgt), embed_size, tgt_pad_token_idx)\n",
    "\n",
    "class NMT(nn.Module):\n",
    "    \"\"\" Simple Neural Machine Translation Model:\n",
    "        - Bidrectional LSTM Encoder\n",
    "        - Unidirection LSTM Decoder\n",
    "        - Global Attention Model (Luong, et al. 2015)\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, hidden_size, vocab, dropout_rate=0.2):\n",
    "        super(NMT, self).__init__()\n",
    "        self.model_embeddings = ModelEmbeddings(embed_size, vocab)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.vocab = vocab\n",
    "\n",
    "        # default values\n",
    "        self.encoder = None \n",
    "        self.decoder = None\n",
    "        self.h_projection = None\n",
    "        self.c_projection = None\n",
    "        self.att_projection = None\n",
    "        self.combined_output_projection = None\n",
    "        self.target_vocab_projection = None\n",
    "        self.dropout = None\n",
    "        # For sanity check only, not relevant to implementation\n",
    "        self.gen_sanity_check = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def decode(self, enc_hiddens: torch.Tensor, enc_masks: torch.Tensor,\n",
    "                dec_init_state: Tuple[torch.Tensor, torch.Tensor], target_padded: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute combined output vectors for a batch.\n",
    "\n",
    "        @param enc_hiddens (Tensor): Hidden states (b, src_len, h*2), where\n",
    "                                     b = batch size, src_len = maximum source sentence length, h = hidden size.\n",
    "        @param enc_masks (Tensor): Tensor of sentence masks (b, src_len), where\n",
    "                                     b = batch size, src_len = maximum source sentence length.\n",
    "        @param dec_init_state (tuple(Tensor, Tensor)): Initial state and cell for decoder\n",
    "        @param target_padded (Tensor): Gold-standard padded target sentences (tgt_len, b), where\n",
    "                                       tgt_len = maximum target sentence length, b = batch size. \n",
    "\n",
    "        @returns combined_outputs (Tensor): combined output tensor  (tgt_len, b,  h), where\n",
    "                                        tgt_len = maximum target sentence length, b = batch_size,  h = hidden size\n",
    "        \"\"\"\n",
    "        # Chop of the <END> token for max length sentences.\n",
    "        target_padded = target_padded[:-1]\n",
    "\n",
    "        # Initialize the decoder state (hidden and cell)\n",
    "        dec_state = dec_init_state\n",
    "\n",
    "        # Initialize previous combined output vector o_{t-1} as zero\n",
    "        batch_size = enc_hiddens.size(0)\n",
    "        o_prev = torch.zeros(batch_size, self.hidden_size, device='cpu')\n",
    "\n",
    "        # Initialize a list we will use to collect the combined output o_t on each step\n",
    "        combined_outputs = []\n",
    "\n",
    "        enc_hiddens_proj = self.att_projection(enc_hiddens)\n",
    "        Y = self.model_embeddings.target(target_padded)\n",
    "        Y_ts = torch.split(Y, 1)\n",
    "        for Y_t in Y_ts:\n",
    "            Y_t = torch.squeeze(Y_t)\n",
    "            Ybar_t = torch.cat((Y_t, o_prev), 1)\n",
    "            dec_state, o_t, _ = self.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj,\n",
    "                                                        enc_masks)\n",
    "            combined_outputs.append(o_t.tolist())\n",
    "            o_prev = o_t\n",
    "        combined_outputs = torch.stack(combined_outputs, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca86c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61b609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3321270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bec98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2indices(sents):\n",
    "    \"\"\" Convert list of words or list of sentences of words\n",
    "    into list or list of list of indices.\n",
    "    @param sents (list[str] or list[list[str]]): sentence(s) in words\n",
    "    @return word_ids (list[int] or list[list[int]]): sentence(s) in indices\n",
    "    \"\"\"\n",
    "    if type(sents[0]) == list:\n",
    "        return [[[w] for w in s] for s in sents]\n",
    "    else:\n",
    "        return [[w] for w in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72509b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d12ad475",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f29437e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 5, 3]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.gather(0, torch.tensor([[2,1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d1e77e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings): ModelEmbeddings(\n",
       "    (source): Embedding(77, 3, padding_idx=0)\n",
       "    (target): Embedding(85, 3, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7c890581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings): ModelEmbeddings(\n",
       "    (source): Embedding(77, 3, padding_idx=0)\n",
       "    (target): Embedding(85, 3, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "mlds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
